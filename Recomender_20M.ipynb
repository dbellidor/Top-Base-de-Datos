{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import HiveContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#sc = SparkContext('local', 'pyspark')\n",
    "#sqlContext = HiveContext(sc)\n",
    "#·spark = SparkSession.builder \\\n",
    "#   .master(\"local\") \\\n",
    "#   .appName(\"Recomendador\") \\\n",
    "#   .config(\"spark.executor.memory\", '5gb') \\\n",
    "#   .config(\"spark.executor.heartbeatInterval\", \"10000000\") \\\n",
    "#   .config(\"spark.network.timeout\" , \"10000000\") \n",
    "#   .getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Linear Regression Model\") \\\n",
    "   .config(\"spark.driver.memory\", \"14g\") \\\n",
    "   .config(\"spark.executor.memory\", '12gb') \\\n",
    "   .config(\"spark.driver.maxResultSize\", '12gb') \\\n",
    "   .getOrCreate()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movieId='1', title='Toy Story (1995)', genres='Adventure|Animation|Children|Comedy|Fantasy'),\n",
       " Row(movieId='2', title='Jumanji (1995)', genres='Adventure|Children|Fantasy'),\n",
       " Row(movieId='3', title='Grumpier Old Men (1995)', genres='Comedy|Romance'),\n",
       " Row(movieId='4', title='Waiting to Exhale (1995)', genres='Comedy|Drama|Romance'),\n",
       " Row(movieId='5', title='Father of the Bride Part II (1995)', genres='Comedy')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "movies = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option('header', 'true')\\\n",
    "  .load('movies.csv')\n",
    "movies.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(userId='1', movieId='2', rating='3.5', timestamp='1112486027'),\n",
       " Row(userId='1', movieId='29', rating='3.5', timestamp='1112484676'),\n",
       " Row(userId='1', movieId='32', rating='3.5', timestamp='1112484819'),\n",
       " Row(userId='1', movieId='47', rating='3.5', timestamp='1112484727'),\n",
       " Row(userId='1', movieId='50', rating='3.5', timestamp='1112484580')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option('header', 'true')\\\n",
    "  .load('ratings.csv')\n",
    "ratings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.3\n"
     ]
    }
   ],
   "source": [
    "print (spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions for the movies DataFrame: 1\n",
      "Number of partitions for the ratings DataFrame: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"Number of partitions for the movies DataFrame: \" + str(movies.rdd.getNumPartitions()))\n",
    "print (\"Number of partitions for the ratings DataFrame: \" + str(ratings.rdd.getNumPartitions()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions for the ratings DataFrame: 4\n",
      "Number of partitions for the repartitionedRatings DataFrame: 10\n"
     ]
    }
   ],
   "source": [
    "repartitionedRatings = ratings.repartition(10)\n",
    "print (\"Number of partitions for the ratings DataFrame: \" + str(ratings.rdd.getNumPartitions()))\n",
    "print (\"Number of partitions for the repartitionedRatings DataFrame: \" + str(repartitionedRatings.rdd.getNumPartitions()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 20000263\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of ratings: \" + str(repartitionedRatings.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: string, movieId: string, rating: string, timestamp: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repartitionedRatings.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 20000263\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of ratings: \" + str(repartitionedRatings.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------------------+-------------------------------------------+\n",
      "|movieId|title                                |genres                                     |\n",
      "+-------+-------------------------------------+-------------------------------------------+\n",
      "|1      |Toy Story (1995)                     |Adventure|Animation|Children|Comedy|Fantasy|\n",
      "|2      |Jumanji (1995)                       |Adventure|Children|Fantasy                 |\n",
      "|3      |Grumpier Old Men (1995)              |Comedy|Romance                             |\n",
      "|4      |Waiting to Exhale (1995)             |Comedy|Drama|Romance                       |\n",
      "|5      |Father of the Bride Part II (1995)   |Comedy                                     |\n",
      "|6      |Heat (1995)                          |Action|Crime|Thriller                      |\n",
      "|7      |Sabrina (1995)                       |Comedy|Romance                             |\n",
      "|8      |Tom and Huck (1995)                  |Adventure|Children                         |\n",
      "|9      |Sudden Death (1995)                  |Action                                     |\n",
      "|10     |GoldenEye (1995)                     |Action|Adventure|Thriller                  |\n",
      "|11     |American President, The (1995)       |Comedy|Drama|Romance                       |\n",
      "|12     |Dracula: Dead and Loving It (1995)   |Comedy|Horror                              |\n",
      "|13     |Balto (1995)                         |Adventure|Animation|Children               |\n",
      "|14     |Nixon (1995)                         |Drama                                      |\n",
      "|15     |Cutthroat Island (1995)              |Action|Adventure|Romance                   |\n",
      "|16     |Casino (1995)                        |Crime|Drama                                |\n",
      "|17     |Sense and Sensibility (1995)         |Drama|Romance                              |\n",
      "|18     |Four Rooms (1995)                    |Comedy                                     |\n",
      "|19     |Ace Ventura: When Nature Calls (1995)|Comedy                                     |\n",
      "|20     |Money Train (1995)                   |Action|Comedy|Crime|Drama|Thriller         |\n",
      "+-------+-------------------------------------+-------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "movies.show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_file_name = 'movies.csv'\n",
    "ratings_file_name = 'ratings.csv'\n",
    "\n",
    "movies = spark.read.csv(movies_file_name, header=True, inferSchema=True).repartition(10).cache()\n",
    "ratings = spark.read.csv(ratings_file_name, header=True, inferSchema=True).repartition(10).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "movies.printSchema()\n",
    "ratings.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+--------------------+\n",
      "|summary|            userId|          movieId|            rating|           timestamp|\n",
      "+-------+------------------+-----------------+------------------+--------------------+\n",
      "|  count|          20000263|         20000263|          20000263|            20000263|\n",
      "|   mean| 69045.87258292554|9041.567330339605|3.5255285642993797|1.1009179216771154E9|\n",
      "| stddev|40038.626653162835|19789.47744541314| 1.051988919294246|1.6216942478272852E8|\n",
      "|    min|                 1|                1|               0.5|           789652004|\n",
      "|    max|            138493|           131262|               5.0|          1427784002|\n",
      "+-------+------------------+-----------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different users: 138493\n",
      "Number of different movies: 26744\n",
      "Number of movies with at least one rating strictly higher than 4: 17218\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print (\"Number of different users: \" + str(ratings.select('userId').distinct().count()))\n",
    "print (\"Number of different movies: \" + str(ratings.select('movieId').distinct().count()))\n",
    "print (\"Number of movies with at least one rating strictly higher than 4: \" + str(ratings.filter('rating > 4').select('movieId').distinct().count()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|   nb|\n",
      "+-----+\n",
      "|17218|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.createOrReplaceTempView('ratings')\n",
    "spark.sql(\"SELECT COUNT(DISTINCT(movieId)) AS nb FROM ratings WHERE rating > 4\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='userId', _c1='movieId', _c2='rating', _c3='timestamp'),\n",
       " Row(_c0='1', _c1='2', _c2='3.5', _c3='1112486027')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_url = ratings_file_name\n",
    "sql = \"SELECT * FROM csv.`\" + ratings_url + \"`\"\n",
    "spark.sql(sql).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "\n",
    "#ratings.toPandas().head()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#import seaborn as sns\n",
    "#%matplotlib inline\n",
    "\n",
    "#ratingsPandas = ratings.toPandas()\n",
    "#sns.lmplot(x='userId', y='movieId', data=ratingsPandas, fit_reg=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.palplot(sns.diverging_palette(10, 133, sep=80, n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#lm = sns.lmplot(x='userId', y='movieId', hue='rating', data=ratingsPandas, fit_reg=False, size=10, aspect=2, palette=sns.diverging_palette(10, 133, sep=80, n=10))\n",
    "#axes = lm.axes\n",
    "#axes[0,0].set_ylim(0,163949) # max movieId is 163949\n",
    "#axes[0,0].set_xlim(0,671) # max userId is 671\n",
    "#lm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.violinplot([ratingsPandas.rating])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----------+-----------+-----------------+\n",
      "|nb_users|nb_movies|nb_ratings|matrix_size|       percentage|\n",
      "+--------+---------+----------+-----------+-----------------+\n",
      "|  138493|    26744|  20000263| 3703856792|0.539984781355445|\n",
      "+--------+---------+----------+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT *, 100 * nb_ratings/matrix_size AS percentage\n",
    "    FROM (\n",
    "        SELECT nb_users, nb_movies, nb_ratings, nb_users * nb_movies AS matrix_size\n",
    "        FROM (\n",
    "            SELECT COUNT(*) AS nb_ratings, COUNT(DISTINCT(movieId)) AS nb_movies, COUNT(DISTINCT(userId)) AS nb_users\n",
    "            FROM ratings\n",
    "        )\n",
    "    )\n",
    "\"\"\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "model = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\").fit(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+\n",
      "|userId|movieId|rating| timestamp|prediction|\n",
      "+------+-------+------+----------+----------+\n",
      "| 74757|    148|   3.5|1064853335|  2.773692|\n",
      "| 96393|    148|   3.0| 970170090|  2.680015|\n",
      "| 53338|    148|   1.0| 834319825| 2.6870646|\n",
      "| 22684|    148|   4.0| 832057800| 2.8577313|\n",
      "| 97435|    148|   4.0|1042483722|  2.987529|\n",
      "|136222|    148|   2.0| 849125057| 2.4274337|\n",
      "|137949|    148|   4.0| 950909863| 3.1353018|\n",
      "| 19067|    148|   2.0| 833483264| 1.5067592|\n",
      "| 87301|    148|   2.0| 974945135| 2.6679068|\n",
      "| 88527|    148|   2.0| 965659724|  2.308216|\n",
      "|108726|    148|   3.0| 948831793| 2.8115225|\n",
      "| 92852|    148|   3.0| 839813031| 2.5579293|\n",
      "|123246|    148|   3.0| 833017056|  3.155644|\n",
      "| 20132|    148|   3.0|1021775793|  2.655308|\n",
      "| 22884|    148|   3.0| 944947868| 2.5870566|\n",
      "| 96427|    148|   3.0| 860111242| 3.0752568|\n",
      "| 10303|    148|   3.0| 940857361| 2.9307692|\n",
      "| 36821|    148|   4.0| 979367598|  2.936095|\n",
      "| 83090|    148|   2.0|1030400425| 1.9887944|\n",
      "| 44979|    148|   3.0| 830778220|  2.996578|\n",
      "+------+-------+------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(ratings)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El error cuadrático medio para nuestro modelo es: 0.779277791407944\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "print (\"El error cuadrático medio para nuestro modelo es:: \" + str(evaluator.evaluate(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "(trainingRatings, testRatings) = ratings.randomSplit([80.0, 20.0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
    "model = als.fit(trainingRatings)\n",
    "predictions = model.transform(testRatings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+\n",
      "|userId|movieId|rating| timestamp|prediction|\n",
      "+------+-------+------+----------+----------+\n",
      "| 88527|    148|   2.0| 965659724| 2.2641451|\n",
      "| 20132|    148|   3.0|1021775793| 2.7054284|\n",
      "| 13170|    148|   3.0| 885524891| 1.1319512|\n",
      "| 60081|    148|   2.0| 837850255| 2.8961163|\n",
      "|130122|    148|   3.0| 837811440| 2.8323267|\n",
      "| 54726|    148|   5.0| 832703670| 3.3310623|\n",
      "| 94994|    148|   4.0| 833661877| 2.7445264|\n",
      "| 46380|    148|   4.0| 828462479| 2.8272812|\n",
      "| 75781|    148|   3.0| 895230335| 2.8665926|\n",
      "| 77165|    148|   3.0| 840699559|  2.869279|\n",
      "| 68242|    148|   3.0|1047397251| 2.1411123|\n",
      "| 35498|    148|   3.0| 848777439| 2.7368045|\n",
      "| 81824|    148|   3.0| 847089543|   2.54909|\n",
      "|109910|    148|   2.0| 907093395| 2.2866628|\n",
      "| 86098|    148|   3.0| 842162037| 2.7881277|\n",
      "| 10434|    148|   3.0| 837033792| 2.6159565|\n",
      "|127911|    148|   1.0| 935288631|  2.132514|\n",
      "| 91231|    148|   4.0|1025350818| 2.7349982|\n",
      "| 89588|    148|   3.0|1049216998| 2.9823601|\n",
      "| 22584|    148|   2.0| 835094487| 2.8238618|\n",
      "+------+-------+------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean squared error for our model is: nan\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "print (\"The root mean squared error for our model is: \" + str(evaluator.evaluate(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average rating in the dataset is: 3.5255285642993797\n",
      "The root mean squared error for our model is: 0.805761885113466\n"
     ]
    }
   ],
   "source": [
    "avgRatings = ratings.select('rating').groupBy().avg().first()[0]\n",
    "print (\"The average rating in the dataset is: \" + str(avgRatings))\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "print (\"The root mean squared error for our model is: \" + str(evaluator.evaluate(predictions.na.fill(avgRatings))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean squared error for our model is: 0.805617065671183\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "print (\"The root mean squared error for our model is: \" + str(evaluator.evaluate(predictions.na.drop())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeatALS(data, k=3, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", metricName=\"rmse\"):\n",
    "    evaluations = []\n",
    "    for i in range(0, k):  \n",
    "        (trainingSet, testingSet) = data.randomSplit([k-1.0, 1.0])\n",
    "        als = ALS(userCol=userCol, itemCol=itemCol, ratingCol=ratingCol)\n",
    "        model = als.fit(trainingSet)\n",
    "        predictions = model.transform(testingSet)\n",
    "        evaluator = RegressionEvaluator(metricName=metricName, labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "        evaluation = evaluator.evaluate(predictions.na.drop())\n",
    "        print (\"Loop \" + str(i+1) + \": \" + metricName + \" = \" + str(evaluation))\n",
    "        evaluations.append(evaluation)\n",
    "    return sum(evaluations)/float(len(evaluations))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1: rmse = 0.8056646639129105\n",
      "Loop 2: rmse = 0.8061619472392852\n",
      "Loop 3: rmse = 0.8058760169694468\n",
      "Loop 4: rmse = 0.8063192947753541\n",
      "RMSE = 0.8060054807242492\n"
     ]
    }
   ],
   "source": [
    "print (\"RMSE = \" + str(repeatALS(ratings, k=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kfoldALS(data, k=3, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", metricName=\"rmse\"):\n",
    "    evaluations = []\n",
    "    weights = [1.0] * k\n",
    "    splits = data.randomSplit(weights)\n",
    "    for i in range(0, k):  \n",
    "        testingSet = splits[i]\n",
    "        trainingSet = spark.createDataFrame(sc.emptyRDD(), data.schema)\n",
    "        for j in range(0, k):\n",
    "            if i == j:\n",
    "                continue\n",
    "            else:\n",
    "                trainingSet = trainingSet.union(splits[j])\n",
    "        als = ALS(userCol=userCol, itemCol=itemCol, ratingCol=ratingCol)\n",
    "        model = als.fit(trainingSet)\n",
    "        predictions = model.transform(testingSet)\n",
    "        evaluator = RegressionEvaluator(metricName=metricName, labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "        evaluation = evaluator.evaluate(predictions.na.drop())\n",
    "        print (\"Loop \" + str(i+1) + \": \" + metricName + \" = \" + str(evaluation))\n",
    "        evaluations.append(evaluation)\n",
    "    return sum(evaluations)/float(len(evaluations))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1: rmse = 0.8060031982561844\n",
      "Loop 2: rmse = 0.8060467963052774\n",
      "Loop 3: rmse = 0.8059659720574583\n",
      "Loop 4: rmse = 0.805918756109011\n",
      "RMSE = 0.8059836806819829\n"
     ]
    }
   ],
   "source": [
    "print (\"RMSE = \" + str(kfoldALS(ratings, k=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1: rmse = 0.8048771593190648\n",
      "Loop 2: rmse = 0.8054179576399685\n",
      "Loop 3: rmse = 0.804122110369164\n",
      "Loop 4: rmse = 0.804993093327777\n",
      "Loop 5: rmse = 0.8052123895992385\n",
      "Loop 6: rmse = 0.8051736224763585\n",
      "Loop 7: rmse = 0.8047446017929901\n",
      "Loop 8: rmse = 0.8052915758751963\n",
      "Loop 9: rmse = 0.8053031155619893\n",
      "Loop 10: rmse = 0.8049827538797963\n",
      "RMSE = 0.8050118379841542\n"
     ]
    }
   ],
   "source": [
    "print (\"RMSE = \" + str(kfoldALS(ratings, k=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "def recommendMovies(model, user, nbRecommendations):\n",
    "    # Create a Spark DataFrame with the specified user and all the movies listed in the ratings DataFrame\n",
    "    dataSet = ratings.select(\"movieId\").distinct().withColumn(\"userId\", lit(user))\n",
    "\n",
    "    # Create a Spark DataFrame with the movies that have already been rated by this user\n",
    "    moviesAlreadyRated = ratings.filter(ratings.userId == user).select(\"movieId\", \"userId\")\n",
    "\n",
    "    # Apply the recommender system to the data set without the already rated movies to predict ratings\n",
    "    predictions = model.transform(dataSet.subtract(moviesAlreadyRated)).dropna().orderBy(\"prediction\", ascending=False).limit(nbRecommendations).select(\"movieId\", \"prediction\")\n",
    "\n",
    "    # Join with the movies DataFrame to get the movies titles and genres\n",
    "    recommendations = predictions.join(movies, predictions.movieId == movies.movieId).select(predictions.movieId, movies.title, movies.genres, predictions.prediction)\n",
    "\n",
    "    recommendations.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 133:\n",
      "+-------+-----------------------------------------------------+--------------------+----------+\n",
      "|movieId|title                                                |genres              |prediction|\n",
      "+-------+-----------------------------------------------------+--------------------+----------+\n",
      "|112473 |Stuart: A Life Backward (2007)                       |Drama               |4.485329  |\n",
      "|56869  |Drained (O cheiro do Ralo) (2006)                    |Comedy              |4.470287  |\n",
      "|81117  |Moth, The (Cma) (1980)                               |Drama               |4.4433036 |\n",
      "|100553 |Frozen Planet (2011)                                 |Documentary         |4.4707317 |\n",
      "|120134 |Doggiewoggiez! Poochiewoochiez! (2012)               |Comedy              |4.5738916 |\n",
      "|130347 |Bill Hicks: Sane Man (1989)                          |Comedy              |4.7635846 |\n",
      "|116183 |It's Love I'm After (1937)                           |Comedy              |4.498064  |\n",
      "|101717 |Elusive Summer of '68, The (Varljivo leto '68) (1984)|Comedy|Drama|Romance|4.582958  |\n",
      "|121029 |No Distance Left to Run (2010)                       |Documentary         |4.7009196 |\n",
      "|112423 |I Belong (Som du ser meg) (2012)                     |Drama               |4.456054  |\n",
      "+-------+-----------------------------------------------------+--------------------+----------+\n",
      "\n",
      "Recommendations for user 471:\n",
      "+-------+----------------------------------------+--------------------+----------+\n",
      "|movieId|title                                   |genres              |prediction|\n",
      "+-------+----------------------------------------+--------------------+----------+\n",
      "|112473 |Stuart: A Life Backward (2007)          |Drama               |4.673992  |\n",
      "|95776  |Bob Funk (2009)                         |Comedy|Romance      |4.794278  |\n",
      "|120821 |The War at Home (1979)                  |Documentary|War     |4.808825  |\n",
      "|30764  |Mahabharata, The (1989)                 |Action|Drama|War    |4.7324038 |\n",
      "|26978  |Kiss or Kill (1997)                     |Crime|Drama|Thriller|4.6534724 |\n",
      "|117907 |My Brother Tom (2001)                   |Drama               |4.699924  |\n",
      "|128187 |Freedom Song (2000)                     |Drama               |4.7192993 |\n",
      "|86237  |Connections (1978)                      |Documentary         |4.682569  |\n",
      "|121029 |No Distance Left to Run (2010)          |Documentary         |4.6497717 |\n",
      "|77736  |Crazy Stone (Fengkuang de shitou) (2006)|Comedy|Crime        |5.303723  |\n",
      "+-------+----------------------------------------+--------------------+----------+\n",
      "\n",
      "Recommendations for user 496:\n",
      "+-------+--------------------------------------------------------------+--------------------------------------+----------+\n",
      "|movieId|title                                                         |genres                                |prediction|\n",
      "+-------+--------------------------------------------------------------+--------------------------------------+----------+\n",
      "|95776  |Bob Funk (2009)                                               |Comedy|Romance                        |5.873374  |\n",
      "|120821 |The War at Home (1979)                                        |Documentary|War                       |5.7448745 |\n",
      "|107623 |2013 Rock and Roll Hall of Fame Induction Ceremony, The (2013)|Documentary|Musical                   |5.4203506 |\n",
      "|102119 |Yesterday Was a Lie (2008)                                    |Drama|Film-Noir|Mystery|Romance|Sci-Fi|5.4733644 |\n",
      "|120134 |Doggiewoggiez! Poochiewoochiez! (2012)                        |Comedy                                |5.475085  |\n",
      "|73365  |Dead Time: Kala (2007)                                        |Crime|Fantasy|Film-Noir|Thriller      |5.4454184 |\n",
      "|117907 |My Brother Tom (2001)                                         |Drama                                 |6.0349784 |\n",
      "|121029 |No Distance Left to Run (2010)                                |Documentary                           |5.542128  |\n",
      "|77736  |Crazy Stone (Fengkuang de shitou) (2006)                      |Comedy|Crime                          |5.61633   |\n",
      "|112423 |I Belong (Som du ser meg) (2012)                              |Drama                                 |5.4924564 |\n",
      "+-------+--------------------------------------------------------------+--------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Recommendations for user 133:\")\n",
    "recommendMovies(model, 133, 10)\n",
    "print (\"Recommendations for user 471:\")\n",
    "recommendMovies(model, 471, 10)\n",
    "print (\"Recommendations for user 496:\")\n",
    "recommendMovies(model, 496, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
